{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading rennet modules\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# py2.7 compat\n",
    "from __future__ import division, print_function\n",
    "from six.moves import zip, range, zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "rennet_data_root = os.path.join(\"..\", \"..\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "***\n",
    "\n",
    "> **NOTE:**\n",
    ">\n",
    "> This is not the original notebook used in double-talk detection research by me (Abdullah).\n",
    "> But it is a faithful and more easy to use copy with some modifications, and some parts skipped.\n",
    ">\n",
    "> You should still be able to use it to meet the main goals of this notebook.\n",
    ">\n",
    "> For anything marked as `[SKIPPED]`, please refer to the following original notebooks in `notebooks/dtfinale/`:\n",
    "> - `2017-08-03-feats-fe_03_p1m-logmel64-win32ms-hop10ms.ipynb`\n",
    "> - `2017-08-04-feats-fe_03_p1-logmel64-win32ms-hop10ms.ipynb`\n",
    "\n",
    "---\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting `logmelspectrogram_64` features for `fe_03_p1`\n",
    "\n",
    "The goal of this notebook is to document how:\n",
    "- features are extracted for the existing exported splits of the dataset\n",
    "    + Assumes that the splits directory structures from previous steps\n",
    "    + Assumes all audio files in all splits are in the standardized audio format (or one that `audioread` can work with):\n",
    "        * format: `wav`\n",
    "        * channels: `mono`\n",
    "        * samplerate: `8000 Hz`\n",
    "    + Features to be extracted with params:\n",
    "        * type: `log10-mel-spectrograms`\n",
    "        * n_mels: `64`\n",
    "        * window_type_stft: `hanning`\n",
    "        * window_len_stft: `0.032 sec`\n",
    "        * hop_len_stft: `0.010 sec`\n",
    "- labels are extracted for the corresponding time-stamps of the extracted features\n",
    "    + Assumes that `ActiveSpeakers` can be read for the dataset from label files\n",
    "        * **and** that all have only two speakers\n",
    "- chunked storage to hdf5 files of the features and corresponding labels is performed for each split, using dask\n",
    "    + chunks have overlap _within_ a call\n",
    "        * chunk_size_axis0: `2**14`\n",
    "        * chunk_overlap_axis0: `2**10`\n",
    "- extra infos are added to the exported\n",
    "    + speaker information for each call's labels added as hdf5 attributes\n",
    "    + ___raw___ Viterbi priors are calculated and added for each split's hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:37.812441",
     "start_time": "2017-08-04T15:44:33.618014"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import namedtuple\n",
    "from itertools import starmap\n",
    "\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import dask as d\n",
    "import dask.array as da\n",
    "from distributed import Client\n",
    "import h5py as h\n",
    "\n",
    "import dask.diagnostics as dg\n",
    "import time\n",
    "from bokeh.io import output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:39.501576",
     "start_time": "2017-08-04T15:44:38.837784"
    }
   },
   "outputs": [],
   "source": [
    "%aimport rennet.datasets.fisher\n",
    "import rennet.datasets.fisher as fe\n",
    "\n",
    "%aimport rennet.utils.audio_utils\n",
    "import rennet.utils.audio_utils as au\n",
    "\n",
    "%aimport rennet.utils.np_utils\n",
    "import rennet.utils.np_utils as nu\n",
    "\n",
    "from rennet.utils.py_utils import recursive_glob, makedirs_with_existok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:40.173248",
     "start_time": "2017-08-04T15:44:40.158664"
    }
   },
   "outputs": [],
   "source": [
    "# dask progress bars and other diagnostics\n",
    "pb = dg.ProgressBar()\n",
    "pb.register()\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "pr = dg.Profiler()\n",
    "pr.register()\n",
    "\n",
    "rpr = dg.ResourceProfiler(dt=0.1)\n",
    "rpr.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params \n",
    "\n",
    "For feature extraction and related tasks like, output file naming, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:42.922629",
     "start_time": "2017-08-04T15:44:42.899416"
    }
   },
   "outputs": [],
   "source": [
    "# The parameters that will be used for extracting logmelspectrogram\n",
    "win_sec = 0.032\n",
    "hop_sec = 0.010\n",
    "nmels = 64\n",
    "window = 'hann'\n",
    "sr = samplerate = 8000\n",
    "nchannels = 1\n",
    "chunking = 2**14  # main axis' size for hdf5 chunked storage\n",
    "chunkovl = 2**10  # overlap between consecutive chunks of the same call, so adding contextual frames doesn't miss frames.\n",
    "\n",
    "n_fft = win_len = int(win_sec * sr)\n",
    "hop_len = int(hop_sec * sr)\n",
    "chunkstep = chunking - chunkovl\n",
    "melfreq = lr.mel_frequencies(n_mels=nmels, fmax=sr//2)\n",
    "\n",
    "print('win-len', win_len)\n",
    "print('hop-len', hop_len)\n",
    "print()\n",
    "print('chunking', chunking)\n",
    "print('chunkovl', chunkovl)\n",
    "print('chunkstep', chunkstep)\n",
    "print()\n",
    "print('mel-frequencies ({})\\n'.format(len(melfreq)), melfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roots & Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources \n",
    "\n",
    "Where the pre-split wav and label exports are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:45.597044",
     "start_time": "2017-08-04T15:44:45.582422"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up roots for sources\n",
    "\n",
    "working_data_dir = os.path.join(rennet_data_root, 'working')\n",
    "\n",
    "provider = 'fisher'\n",
    "dataset = 'fe_03_p1'\n",
    "export_name = 'wav-8k-mono'\n",
    "\n",
    "\n",
    "# Root path to where the splits are\n",
    "\n",
    "splits_root = os.path.join(working_data_dir, provider, dataset, export_name)\n",
    "# check if it exists\n",
    "if not os.path.exists(splits_root):\n",
    "    raise RuntimeError(\"SPLITS_ROOT not found at: \\n {}\".format(splits_root))\n",
    "    \n",
    "print('SPLITS_ROOT', splits_root, '', sep='\\n')\n",
    "\n",
    "# No errors means all okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:49.109364",
     "start_time": "2017-08-04T15:44:49.081049"
    }
   },
   "outputs": [],
   "source": [
    "# Making glob queries for audio, label and calldata files\n",
    "\n",
    "export_val_dir = os.path.join(splits_root, 'val')\n",
    "val_audios_dir = os.path.join(export_val_dir, 'audios', 'data')\n",
    "val_audios_glob_str = (val_audios_dir, \"*.wav\")\n",
    "val_labels_dir = os.path.join(export_val_dir, 'labels', 'data')\n",
    "val_labels_glob_str = (val_labels_dir, \"*.txt\")\n",
    "\n",
    "export_trn_dir = os.path.join(splits_root, 'train')\n",
    "trn_audios_dir = os.path.join(export_trn_dir, 'audios', 'data')\n",
    "trn_audios_glob_str = (trn_audios_dir, \"*.wav\")\n",
    "trn_labels_dir = os.path.join(export_trn_dir, 'labels', 'data')\n",
    "trn_labels_glob_str = (trn_labels_dir, \"*.txt\")\n",
    "\n",
    "export_tst_dir = os.path.join(splits_root, 'test')\n",
    "tst_audios_dir = os.path.join(export_tst_dir, 'audios', 'data')\n",
    "tst_audios_glob_str = (tst_audios_dir, \"*.wav\")\n",
    "tst_labels_dir = os.path.join(export_tst_dir, 'labels', 'data')\n",
    "tst_labels_glob_str = (tst_labels_dir, \"*.txt\")\n",
    "\n",
    "calldata_glob_str = (os.path.join(export_val_dir, 'labels'), \"*calldata.tbl\")\n",
    "\n",
    "print(\"\\nCHECK IF THE QUERIES MAKE SENSE\\n\")\n",
    "print(\"Calldata Query:\\n\", calldata_glob_str)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Audios Query:\\n\", val_audios_glob_str)\n",
    "print()\n",
    "print(\"Validation Labels Query:\\n\", val_labels_glob_str)\n",
    "print(\"\\n\")\n",
    "print(\"Train Audios Query:\\n\", trn_audios_glob_str)\n",
    "print()\n",
    "print(\"Train Labels Query:\\n\", trn_labels_glob_str)\n",
    "print(\"\\n\")\n",
    "print(\"Test Audios Query:\\n\", tst_audios_glob_str)\n",
    "print()\n",
    "print(\"Test Labels Query:\\n\", tst_labels_glob_str)\n",
    "\n",
    "# You should look at the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:50.003866",
     "start_time": "2017-08-04T15:44:49.897092"
    }
   },
   "outputs": [],
   "source": [
    "# find the calldata.tbl file\n",
    "# NOTE: We only use the calldata.tbl from the val split\n",
    "# it is the same file for all the splits\n",
    "\n",
    "calldata_fp = list(recursive_glob(*calldata_glob_str))\n",
    "\n",
    "if len(calldata_fp) > 1:\n",
    "    warnings.warn(\"More than one calldata file found\")\n",
    "elif len(calldata_fp) < 1:\n",
    "    raise RuntimeError(\"Calldata file was not found\")\n",
    "else:\n",
    "    calldata_fp = calldata_fp[0]\n",
    "    print(\"CALLDATA filepath:\", calldata_fp, sep='\\n')\n",
    "    \n",
    "calldatas = fe.AllCallData.from_file(calldata_fp)\n",
    "\n",
    "print(\"\\n\\nCALLDATA read for {} callids\\n\".format(len(calldatas.allcalldata)))\n",
    "print(\"\\nExample calldata:\\n\")\n",
    "print(calldatas['00086'], sep='\\n')\n",
    "\n",
    "# No errors means all okay reading call data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:51.006477",
     "start_time": "2017-08-04T15:44:50.985001"
    }
   },
   "outputs": [],
   "source": [
    "# helpers\n",
    "\n",
    "AudioLabelPair = namedtuple('AudioLabelPair', 'audio,label')\n",
    "\n",
    "def fn_for_fp(fp):\n",
    "    return os.path.basename(fp).split(\".\")[0]\n",
    "\n",
    "audio_metas = au.get_audio_metadata\n",
    "parse_label = lambda fp: fe.ActiveSpeakers.from_file(fp, warn_duplicates=False, allcalldata=calldatas)\n",
    "\n",
    "def find_validate_pair_split(audios_glob_str, labels_glob_str, split_name, n_expected_pairs=None):\n",
    "    audio_fps = sorted(recursive_glob(*audios_glob_str))\n",
    "    label_fps = sorted(recursive_glob(*labels_glob_str))\n",
    "    \n",
    "    if n_expected_pairs is not None:\n",
    "        assert len(audio_fps) == n_expected_pairs,\\\n",
    "            \"{} audio files found, expected {}, check your query\".format(len(audio_fps), n_expected_pairs)\n",
    "        assert len(label_fps) == n_expected_pairs,\\\n",
    "            \"{} label files found, expected {}, check your query\".format(len(label_fps), n_expected_pairs)\n",
    "    else:\n",
    "        assert len(audio_fps) > 0, \"No audio files found, check your query\"\n",
    "        assert len(label_fps) > 0, \"No label files found, check your query\"\n",
    "\n",
    "#     assert len(audio_fps) == len(label_fps),\\\n",
    "#         \"\\nMISMATCH: audios : {} v/s {} labels\".format(len(audio_fps), len(label_fps))\n",
    "\n",
    "    # make pairs with zip\n",
    "    pairs = list(starmap(\n",
    "        AudioLabelPair,\n",
    "        zip(\n",
    "            map(audio_metas, audio_fps), \n",
    "            map(parse_label, label_fps))))\n",
    "\n",
    "    # Assert that all pairs have same callid\n",
    "    # NOTE: here, we check the filename, which has the callid\n",
    "    assert all(fn_for_fp(a.filepath) == fn_for_fp(l.sourcefile) for a, l in pairs),\\\n",
    "        \"\\nMISMATCH: callids between audio and label, check filenames, ordering, or missing/substitutions\"\n",
    "\n",
    "    # print some stats for feedback\n",
    "    print(\"{}:#############################################################\\n\\n\".format(split_name.upper()),\n",
    "          \"Total Pairs: {}\\n\\n\".format(len(pairs)),\n",
    "          \"For Example:\\n\\n{}\\n\\n...\".format(\n",
    "              \"\\n...\\n\\n\".join(\"{}\\n{}\".format(a, l[:3]) \n",
    "                        for a, l in pairs[:2])))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:53.041325",
     "start_time": "2017-08-04T15:44:52.763553"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VAL: Find all audio and label files, single list per split\n",
    "val_pairs = find_validate_pair_split(val_audios_glob_str, val_labels_glob_str, 'val', 99)\n",
    "\n",
    "# No errors means all okay for VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:56.950090",
     "start_time": "2017-08-04T15:44:54.147150"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRN: Find all audio and label files, single list per split\n",
    "trn_pairs = find_validate_pair_split(trn_audios_glob_str, trn_labels_glob_str, 'trn', 5200)\n",
    "\n",
    "# No errors means all okay for TRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:44:59.005515",
     "start_time": "2017-08-04T15:44:57.817493"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TST: Find all audio and label files, single list per split\n",
    "tst_pairs = find_validate_pair_split(tst_audios_glob_str, tst_labels_glob_str, 'tst', 551)\n",
    "\n",
    "# No errors means all okay for TST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit Training Set to first 1200 calls _from the original training split_\n",
    "\n",
    "Look for more explanation in the analysis and export notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_pairs = trn_pairs[:1200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinks\n",
    "\n",
    "Where the exported features will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:17.033814",
     "start_time": "2017-08-04T15:45:17.021237"
    }
   },
   "outputs": [],
   "source": [
    "pickles_root = os.path.join(splits_root, 'pickles')  # Root where the directory with h5 will go\n",
    "makedirs_with_existok(pickles_root, exist_ok=True)\n",
    "\n",
    "# Pattern for naming the dir inside the pickles root\n",
    "datestamp = time.strftime(\"%Y%m%d\")\n",
    "pattern = \"{}-logmel{}-win{}ms-hop{}ms\".format(datestamp, nmels, \n",
    "                                                        int(win_sec*1000), \n",
    "                                                        int(hop_sec*1000))\n",
    "\n",
    "pickles_dir = os.path.join(pickles_root, pattern)\n",
    "\n",
    "print(\"Export Directory (was created)\\n\", pickles_dir, sep='\\n')\n",
    "print('\\n\\n')\n",
    "\n",
    "fn_h5 = lambda splitname: \"{}.h5\".format(splitname)\n",
    "val_h5 = os.path.join(pickles_dir, fn_h5(\"val\"))\n",
    "trn_h5 = os.path.join(pickles_dir, fn_h5(\"trn\"))\n",
    "tst_h5 = os.path.join(pickles_dir, fn_h5(\"tst\"))\n",
    "\n",
    "print(\"Export Filepaths\\n\", \n",
    "      val_h5, '',\n",
    "      trn_h5, '',\n",
    "      tst_h5, '',\n",
    "      sep='\\n')\n",
    "\n",
    "makedirs_with_existok(pickles_dir, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Functions\n",
    "\n",
    "These are the main functions that will be used in loading audio, extracting features, and inferring labels.\n",
    "\n",
    "These will be used in pre-flight checks, and later `dask.delayed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:19.723182",
     "start_time": "2017-08-04T15:45:19.689556"
    }
   },
   "outputs": [],
   "source": [
    "# main Python / numpy functions\n",
    "\n",
    "def readaudiodata(pair):\n",
    "    # NOTE: In the pre-flight checks below, we will be testing the method below in \n",
    "    # more detail ... make any changes here if there's something wrong\n",
    "    \n",
    "    a, l = pair.audio, pair.label\n",
    "    \n",
    "    # We only want to get audio samples for which annotations are available\n",
    "    with l.samplerate_as(a.samplerate):\n",
    "        s = int(max(0, l.min_start))  # first start-time\n",
    "        e = int(min(a.nsamples, l.max_end))  # last end-time\n",
    "                \n",
    "    return lr.load(a.filepath, sr=None)[0][s:e]  # choose samples from s to e\n",
    "\n",
    "\n",
    "def extractfeat(audiodata):\n",
    "    return au.logmelspectrogram(y=audiodata, sr=sr, n_fft=n_fft, hop_len=hop_len, \n",
    "                                window=window, n_mels=nmels,\n",
    "                                # win_len=win_len,  # not necessary\n",
    "                               )\n",
    "\n",
    "def readlabelsdata(pair):\n",
    "    a, l = pair.audio, pair.label\n",
    "    \n",
    "    with l.samplerate_as(a.samplerate):\n",
    "        nsamples = min(a.nsamples, l.max_end) - l.min_start  # number of samples of this call for feat-ext\n",
    "        \n",
    "    endings = fe.samples_for_labelsat(nsamples=nsamples, hop_len=hop_len, win_len=win_len)  # time-stamps for stft based feature vectors\n",
    "    \n",
    "    with l.min_start_as(0, samplerate=a.samplerate):  # shift min_start to 0 because the extracted samples start at min_start\n",
    "        labels = l.labels_at(endings, samplerate=a.samplerate)\n",
    "        \n",
    "    return labels\n",
    "\n",
    "def strided_feat(feat):\n",
    "    return nu.strided_view(feat, win_shape=chunking, step_shape=chunkstep)  # make chunks, w/o copying\n",
    "\n",
    "strided_label = strided_feat\n",
    "    \n",
    "def expected_featlen(pair):\n",
    "    a, l = pair.audio, pair.label\n",
    "    \n",
    "    with l.samplerate_as(a.samplerate):\n",
    "        nsamples = min(a.nsamples, l.max_end) - l.min_start\n",
    "        \n",
    "    return 1 + (nsamples - win_len) // hop_len\n",
    "\n",
    "def expected_stridedfeat_shape(pair):\n",
    "    featlen = expected_featlen(pair)\n",
    "    nstrides = (featlen - chunkovl) // chunkstep\n",
    "    return (nstrides, chunking, nmels)\n",
    "\n",
    "def expected_stridedlabel_shape(pair):\n",
    "    return expected_stridedfeat_shape(pair)[:-1] + (2, )  # only 2 active-speakers for all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:20.373767",
     "start_time": "2017-08-04T15:45:20.294526"
    }
   },
   "outputs": [],
   "source": [
    "# dast.delayed versions of the above ... notice minimum number of args for each\n",
    "\n",
    "d_readaudiodata = d.delayed(readaudiodata, name='audio')  # args=(pair,)\n",
    "\n",
    "d_extractfeat = d.delayed(extractfeat, name='feat')  # args=(audiodata,)\n",
    "# NOTE: Yes, we can split the multiple steps involved in extractfeat\n",
    "# and delay each of them ... but ... let's not\n",
    "# Most amount of time is going to be spent in stft, so then\n",
    "# it will make a lot more sense to do **that** the dasky way ... \n",
    "# and that needs another round of making decisions after checks.\n",
    "# Some other day ...\n",
    "\n",
    "d_stridefeat = d.delayed(strided_feat, name='stridef')  # args=(feat,)\n",
    "\n",
    "d_readlabelsdata = d.delayed(readlabelsdata, name='label')  # args=(pair,)\n",
    "\n",
    "d_stridelabel = d.delayed(strided_label, name='stridel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:21.224604",
     "start_time": "2017-08-04T15:45:20.742526"
    }
   },
   "outputs": [],
   "source": [
    "def steps(pair):\n",
    "    # extract and stride features\n",
    "    audiodata = d_readaudiodata(pair)\n",
    "    feat = d_extractfeat(audiodata)\n",
    "    feat = d_stridefeat(feat)  # make into chunks\n",
    "    \n",
    "    # extract and stride labels\n",
    "    label = d_readlabelsdata(pair)\n",
    "    label = d_stridelabel(label)  # make into chunks\n",
    "    \n",
    "    # for feat. This took some debugging, phew!\n",
    "    xfeatshape = expected_stridedfeat_shape(pair)\n",
    "    feat = da.from_delayed(feat, xfeatshape, np.float64)\n",
    "    feat = da.concatenate(feat)\n",
    "    \n",
    "    # for labels\n",
    "    xlabelshape = expected_stridedlabel_shape(pair)\n",
    "    label = da.from_delayed(label, xlabelshape, np.int)\n",
    "    label = da.concatenate(label)\n",
    "    \n",
    "    # dset paths in hdf5\n",
    "    callid = pair.label.callid\n",
    "    groupid = fe.groupid_for_callid(callid)\n",
    "    topath = \"{}/{}\".format(groupid, callid)\n",
    "    \n",
    "    apath = \"audios/{}\".format(topath)  # e.g. /audios/000/00001\n",
    "    lpath = \"labels/{}\".format(topath)  # e.g. /audios/000/00001\n",
    "    \n",
    "    return (apath, feat), (lpath, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:21.710974",
     "start_time": "2017-08-04T15:45:21.225481"
    }
   },
   "outputs": [],
   "source": [
    "def do_job_for_split(pairs, tofile):\n",
    "    dsets = dict()\n",
    "    \n",
    "    for pair in pairs:\n",
    "        (ap, a), (lp, l) = steps(pair)\n",
    "        \n",
    "        dsets[ap] = a\n",
    "        dsets[lp] = l\n",
    "        \n",
    "    da.to_hdf5(tofile, dsets, \n",
    "               compression='lzf', # compress\n",
    "               fletcher32=True,  # create checksum\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Flight Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:24.461185",
     "start_time": "2017-08-04T15:45:24.440254"
    }
   },
   "outputs": [],
   "source": [
    "# Detailed analysis : Do it for a few files, because it might take a lot of time\n",
    "\n",
    "\n",
    "# First, the helpers\n",
    "def validate_audio_detailed(pair):\n",
    "    assert nchannels <= 2, \"nchannels set by you is > 2, and librosa may do something weird\"\n",
    "    \n",
    "    a, asr = lr.load(pair.audio.filepath, sr=None)\n",
    "    ashape = a.shape\n",
    "    amin, amax = a.min(axis=-1), a.max(axis=-1)\n",
    "    amean = a.mean(axis=-1)\n",
    "    del a\n",
    "    \n",
    "    # check if the samplerates match\n",
    "    assert asr == samplerate, \"samplerate mismatch {} v/s {}\".format(asr, samplerate)\n",
    "    assert asr == pair.audio.samplerate, \"samplerate mismatch {} v/s {}\".format(asr, pair.audio.samplerate)\n",
    "    \n",
    "    # check if nchannels match\n",
    "    # HACK: don't rely on this, cuz librosa, I think, forces things to be at most stereo\n",
    "    assert len(ashape) == nchannels, \"nchannels mismatch {} v/s {}\".format(a.shape, nchannels)\n",
    "    assert len(ashape) == pair.audio.nchannels, \"nchannels mismatch {} v/s {}\".format(ashape, pair.audio.nchannels)\n",
    "    \n",
    "    # check if the nsamples <= labels.max_end\n",
    "    with pair.label.samplerate_as(asr):\n",
    "        me = pair.label.max_end\n",
    "        \n",
    "    assert ashape[-1] >= me, \"nsamples mismatch {} v/s {}\".format(ashape, me)\n",
    "    \n",
    "    # assert that the read audio was normalized\n",
    "    assert np.all(amin >= -1), \"amin not >= -1 at {}\".format(amin)\n",
    "    assert np.all(amax <=  1), \"amax not <= +1 at {}\".format(amax)\n",
    "    assert np.allclose(amean, 0, atol=1e-3), \"amean not close to zero at {}\".format(amean)\n",
    "    \n",
    "    \n",
    "def validate_audio_detailed_pairs(pairs):\n",
    "    for i, pair in enumerate(pairs):\n",
    "        try:\n",
    "            validate_audio_detailed(pair)\n",
    "        except AssertionError as e:\n",
    "            print('AssertionErrors with pair at {}'.format(i))\n",
    "            print(fn_for_fp(pair.audio.filepath))\n",
    "            print(e)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:34.715655",
     "start_time": "2017-08-04T15:45:27.692164"
    }
   },
   "outputs": [],
   "source": [
    "validate_audio_detailed_pairs(val_pairs)\n",
    "\n",
    "# No errors means all okay with the audio files ... hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:35.352210",
     "start_time": "2017-08-04T15:45:35.336805"
    }
   },
   "outputs": [],
   "source": [
    "# The quick analysis basically assumes that our impl of the audio_metadata reader is reliable\n",
    "# Yes, we should validate everything, and ... hopefully ... it will be all quick!\n",
    "\n",
    "def validate_audio_quick(pair):\n",
    "    a = pair.audio\n",
    "    asr = a.samplerate\n",
    "    ashape = (a.nchannels, a.nsamples) if a.nchannels > 1 else (a.nsamples,)\n",
    "    \n",
    "    # check if the samplerates match\n",
    "    assert asr == samplerate, \"samplerate mismatch {} v/s {}\".format(asr, samplerate)\n",
    "    \n",
    "    # check if nchannels match\n",
    "    # HACK: don't rely on this, cuz librosa, I think, forces things to be at most stereo\n",
    "    assert len(ashape) == nchannels, \"nchannels mismatch {} v/s {}\".format(ashape, nchannels)\n",
    "    \n",
    "    # check if the nsamples <= labels.max_end\n",
    "    with pair.label.samplerate_as(asr):\n",
    "        me = pair.label.max_end\n",
    "        \n",
    "    assert ashape[-1] >= me, \"nsamples mismatch {} v/s {}\".format(ashape, me)\n",
    "    \n",
    "    \n",
    "def validate_audio_quick_pairs(pairs):\n",
    "    with_err = []\n",
    "    for i, pair in enumerate(pairs):\n",
    "        try:\n",
    "            validate_audio_quick(pair)\n",
    "        except AssertionError as e:\n",
    "            print('AssertionErrors with pair at {}'.format(i))\n",
    "            print(fn_for_fp(pair.audio.filepath))\n",
    "            print(e)\n",
    "            print()\n",
    "            with_err.append(i)\n",
    "            \n",
    "    return with_err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:36.491483",
     "start_time": "2017-08-04T15:45:36.480308"
    }
   },
   "outputs": [],
   "source": [
    "validate_audio_quick_pairs(val_pairs)\n",
    "\n",
    "# No errors means all okay with the audio files ... hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:37.286372",
     "start_time": "2017-08-04T15:45:37.270855"
    }
   },
   "outputs": [],
   "source": [
    "trn_with_err = validate_audio_quick_pairs(trn_pairs)\n",
    "print(trn_with_err)\n",
    "# No errors means all okay with the audio files ... hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:38.963183",
     "start_time": "2017-08-04T15:45:38.940453"
    }
   },
   "outputs": [],
   "source": [
    "validate_audio_quick_pairs(tst_pairs)\n",
    "\n",
    "# No errors means all okay with the audio files ... hopefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:40.942040",
     "start_time": "2017-08-04T15:45:40.738414"
    }
   },
   "outputs": [],
   "source": [
    "print('Files with errors:', \n",
    "      *[(i, fn_for_fp(trn_pairs[p].audio.filepath)) \n",
    "        for i, p in enumerate(trn_with_err)], \n",
    "      sep='\\n')\n",
    "print()\n",
    "validate_audio_detailed_pairs((trn_pairs[i] for i in trn_with_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:42.752407",
     "start_time": "2017-08-04T15:45:42.683215"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "el = trn_pairs[trn_with_err[i]].label\n",
    "am = trn_pairs[trn_with_err[i]].audio\n",
    "a, asr = lr.load(am.filepath, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:43.428551",
     "start_time": "2017-08-04T15:45:43.422873"
    }
   },
   "outputs": [],
   "source": [
    "with el.min_start_as(0, samplerate=asr): print(el[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:44.018668",
     "start_time": "2017-08-04T15:45:44.014585"
    }
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:45.834400",
     "start_time": "2017-08-04T15:45:45.831264"
    }
   },
   "outputs": [],
   "source": [
    "am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:46.151143",
     "start_time": "2017-08-04T15:45:46.144380"
    }
   },
   "outputs": [],
   "source": [
    "with el.samplerate_as(1): print(el[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:46.588095",
     "start_time": "2017-08-04T15:45:46.584186"
    }
   },
   "outputs": [],
   "source": [
    "am.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Report\n",
    "\n",
    "The audio is smaller than labels!!\n",
    "\n",
    "It is possible that the labels are wrong and the final channels were chopped early.\n",
    "\n",
    "It is also possible that our exporting procedure did this when merging the two channels from \n",
    "the original sph files. But there is no time to rectify that, even if there is a way.\n",
    "\n",
    "Actually, our exporting procedure would have raised an error if the `sph2pipe` passed it along\n",
    "with the missing samples ... but ... oh well ...\n",
    "\n",
    "We will have to keep it in mind when slicing the audio data before feature extraction,\n",
    "and hence, can only rely on the `nsamples` from the metadata (they are correct!), and not\n",
    "from the `max_end` of the labels.\n",
    "\n",
    "Fixes have been added to the main-functions above.\n",
    "\n",
    "Files with errors:\n",
    "0. 'fe_03_00396.wav'\n",
    "1. 'fe_03_00401.wav'\n",
    "2. 'fe_03_00557.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "We want to make sure that the features we will be calculating have the right shape.\n",
    "\n",
    "The values ... well ... I hope you are using reliable ones, because we can't do that deterministically.\n",
    "\n",
    "Finally, the validations will have to extract the features, and hence, will be slow.\n",
    "You will have to settle for smaller set of pairs.\n",
    "\n",
    "Do check for the pairs that caused issues earlier though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:45:48.029582",
     "start_time": "2017-08-04T15:45:48.016726"
    }
   },
   "outputs": [],
   "source": [
    "def validate_featshape_detailed(pair):\n",
    "    am, lb = pair.audio, pair.label\n",
    "    \n",
    "    ad = readaudiodata(pair)\n",
    "    feat = extractfeat(ad)\n",
    "    featshape = feat.shape\n",
    "    \n",
    "    strfeat = strided_feat(feat)\n",
    "    strfeatshape = strfeat.shape\n",
    "    \n",
    "    del feat\n",
    "    del strfeat\n",
    "    \n",
    "    # expectations\n",
    "    xfeatshape = (expected_featlen(pair), nmels)\n",
    "    xstrfeatshape = expected_stridedfeat_shape(pair)\n",
    "    \n",
    "    # assert that they are the expected shapes\n",
    "    assert featshape == xfeatshape, \"Mismatch in featshape: {} v/s {}\".format(featshape, xfeatshape)\n",
    "    assert strfeatshape == xstrfeatshape, \"Mismatch in strfeatshape: {} v/s {}\".format(strfeatshape, xstrfeatshape)\n",
    "    \n",
    "    \n",
    "def validate_featshape_detailed_pairs(pairs):\n",
    "    for i, pair in enumerate(pairs):\n",
    "        try:\n",
    "            validate_featshape_detailed(pair)\n",
    "        except AssertionError as e:\n",
    "            print('AssertionErrors with pair at {}'.format(i))\n",
    "            print(fn_for_fp(pair.audio.filepath))\n",
    "            print(e)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:46:39.041253",
     "start_time": "2017-08-04T15:45:51.380683"
    }
   },
   "outputs": [],
   "source": [
    "# This might be a long running one ... choose few\n",
    "\n",
    "validate_featshape_detailed_pairs(val_pairs[:5])\n",
    "\n",
    "# No errors or printouts means all okay with the shape of the features ... hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:47:24.068166",
     "start_time": "2017-08-04T15:47:22.723210"
    }
   },
   "outputs": [],
   "source": [
    "# Do check for the earlier problem ones!\n",
    "\n",
    "validate_featshape_detailed_pairs([trn_pairs[i] for i in trn_with_err])\n",
    "\n",
    "# No errors or printouts means all okay with the shape of the features ... hopefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "Validate the label shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:47:28.914917",
     "start_time": "2017-08-04T15:47:28.901336"
    }
   },
   "outputs": [],
   "source": [
    "def validate_labelshape(pair):\n",
    "    labels = readlabelsdata(pair)\n",
    "    labelshape = labels.shape\n",
    "    \n",
    "    strlabels = strided_label(labels)\n",
    "    strlabelshape = strlabels.shape\n",
    "    \n",
    "    xlabelshape = (expected_featlen(pair), 2)\n",
    "    xstrlabelshape = expected_stridedlabel_shape(pair)\n",
    "    \n",
    "    assert labelshape == xlabelshape, \"Mismatch in labelshape: {} v/s {}\".format(labelshape, xlabelshape)\n",
    "    assert strlabelshape == xstrlabelshape, \"Mismatch in strlabelshape: {} v/s {}\".format(strlabelshape, xstrlabelshape)\n",
    "    \n",
    "def validate_labelshape_pairs(pairs):\n",
    "    for i, pair in enumerate(pairs):\n",
    "        try:\n",
    "            validate_labelshape(pair)\n",
    "        except AssertionError as e:\n",
    "            print('AssertionErrors with pair at {}'.format(i))\n",
    "            print(fn_for_fp(pair.audio.filepath))\n",
    "            print(e)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:47:30.419977",
     "start_time": "2017-08-04T15:47:30.274487"
    }
   },
   "outputs": [],
   "source": [
    "# This should be quick\n",
    "validate_labelshape_pairs(val_pairs)\n",
    "\n",
    "# No errors or printouts means all okay with the shape of the features ... hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:47:32.755143",
     "start_time": "2017-08-04T15:47:31.391338"
    }
   },
   "outputs": [],
   "source": [
    "# This should be quick\n",
    "validate_labelshape_pairs(trn_pairs)\n",
    "\n",
    "# No errors or printouts means all okay with the shape of the features ... hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:47:34.139622",
     "start_time": "2017-08-04T15:47:33.464863"
    }
   },
   "outputs": [],
   "source": [
    "# This should be quick\n",
    "validate_labelshape_pairs(tst_pairs)\n",
    "\n",
    "# No errors or printouts means all okay with the shape of the features ... hopefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:47:36.125154",
     "start_time": "2017-08-04T15:47:36.089926"
    }
   },
   "outputs": [],
   "source": [
    "def validate_dasksteps_detailed(pair):\n",
    "    xsfs = expected_stridedfeat_shape(pair)\n",
    "    xsls = expected_stridedlabel_shape(pair)\n",
    "    \n",
    "    xdatachunks = ((xsfs[1], ) * xsfs[0], xsfs[2:])\n",
    "    xlabelchunks = ((xsls[1], ) * xsls[0], xsls[2:])\n",
    "    \n",
    "    xdatashape = (xsfs[0] * xsfs[1], ) + xsfs[2:]\n",
    "    xlabelshape = (xsls[0] * xsls[1], ) + xsls[2:]\n",
    "    \n",
    "    callid = pair.label.callid\n",
    "    groupid = fe.groupid_for_callid(callid)\n",
    "    xap = \"{}/{}/{}\".format('audios', groupid, callid)\n",
    "    xlp = \"{}/{}/{}\".format('labels', groupid, callid)\n",
    "    \n",
    "    (ap, a), (lp, l) = steps(pair)\n",
    "    \n",
    "    # assert paths in h5\n",
    "    assert ap == xap, \"Mismatch in audios path: {} v/s {}\".format(ap, xap)\n",
    "    assert lp == xlp, \"Mismatch in labels path: {} v/s {}\".format(lp, xlp)\n",
    "    \n",
    "    # assert chunking\n",
    "    assert a.chunks == xdatachunks, \"Mismatch in audio chunks:\\n{} v/s\\n{}\".format(a.chunks, xdatachunks)\n",
    "    assert l.chunks == xlabelchunks, \"Mismatch in label chunks:\\n{} v/s\\n{}\".format(l.chunks, xlabelchunks)\n",
    "    \n",
    "    # assert shape\n",
    "    assert a.shape == xdatashape, \"Mismatch in audio shape: {} v/s {}\".format(a.shape, xdatashape)\n",
    "    assert l.shape == xlabelshape, \"Mismatch in label shape: {} v/s {}\".format(l.shape, xlabelshape)\n",
    "    \n",
    "    # assert label values\n",
    "    xlabels = np.concatenate(strided_label(readlabelsdata(pair)))\n",
    "    labels = l.compute()\n",
    "    assert np.all(labels == xlabels), \"Mismatch in labels data\"\n",
    "    del xlabels\n",
    "    del labels\n",
    "    \n",
    "    # assert audio values\n",
    "    xdata = np.concatenate(strided_feat(extractfeat(readaudiodata(pair))))\n",
    "    data = a.compute()\n",
    "    assert np.allclose(data, xdata), \"Mismatch in audio data\"\n",
    "    del xdata\n",
    "    del data\n",
    "    \n",
    "def validate_dasksteps_detailed_pairs(pairs):\n",
    "    for i, pair in enumerate(pairs):\n",
    "        try:\n",
    "            validate_dasksteps_detailed(pair)\n",
    "        except AssertionError as e:\n",
    "            print('AssertionErrors with pair at {}'.format(i))\n",
    "            print(fn_for_fp(pair.audio.filepath))\n",
    "            print(e)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T09:41:23.606680Z",
     "start_time": "2017-08-04T09:41:14.750518Z"
    }
   },
   "outputs": [],
   "source": [
    "# This might be a long running one ... choose few\n",
    "validate_dasksteps_detailed_pairs(val_pairs[:5])\n",
    "\n",
    "# No errors means all okay with the dask steps results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T09:41:13.162486Z",
     "start_time": "2017-08-04T09:41:08.582320Z"
    }
   },
   "outputs": [],
   "source": [
    "# This might be a long running one ... choose few\n",
    "validate_dasksteps_detailed_pairs([trn_pairs[i] for i in trn_with_err])\n",
    "\n",
    "# No errors means all okay with the dask steps results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 Export\n",
    "\n",
    "If all the pre-flight checks passed, it's time we finally export the HDF5 files.\n",
    "\n",
    "We may later check on the results ... however ... taking too long may be a bad sign already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T09:50:20.113416Z",
     "start_time": "2017-08-04T09:50:20.109290Z"
    }
   },
   "outputs": [],
   "source": [
    "pr.clear()\n",
    "rpr.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T15:48:50.896734",
     "start_time": "2017-08-04T15:47:49.013465"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(val_h5)\n",
    "do_job_for_split(val_pairs, tofile=val_h5)\n",
    "dg.visualize([pr, rpr])\n",
    "pr.clear()\n",
    "rpr.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T16:27:36.226124",
     "start_time": "2017-08-04T15:48:50.897668"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(trn_h5)\n",
    "do_job_for_split(trn_pairs, tofile=trn_h5)\n",
    "dg.visualize([pr, rpr])\n",
    "pr.clear()\n",
    "rpr.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T16:48:33.959556",
     "start_time": "2017-08-04T16:27:36.228844"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(tst_h5)\n",
    "do_job_for_split(tst_pairs, tofile=tst_h5)\n",
    "dg.visualize([pr, rpr])\n",
    "pr.clear()\n",
    "rpr.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check HDF5, Add Label Infos and Viterbi priors\n",
    "\n",
    "In the `rennet.datasets.fisher` module, `H5ChunkingsReader` was implemented to be able to work with the hdf5 structure that has been exported. \n",
    "The class reads the chunks of each call as per the requirements imposed by `rennet.utils.h5_utils.BaseH5ChunkingsReader`.\n",
    "It also has some convenient `classmethods` to be able to choose which `callids` or `groupids` to work with. \n",
    "Other datasets with different structures may require considerably different such reader.\n",
    "\n",
    "Then, `UnnormedFramewiseInputsProvider` was implemented as well, which allows us to `flow` (read) the data throw a generator without adding contextual frames to the acoustic features, and without applying any normalization.\n",
    "Other, rather esoteric yet very useful `InputsProvider` have also been implemented that do those things.\n",
    "\n",
    "The goal of these classes is to be able to `flow` this data into `keras.model.fit_generator(...)` method later during training, without exploding the memory or being mind-numbingly slow (upto 25x compared to a naive solution).\n",
    "They are quite complicated, especially looking at the class heirarchies, and there have definitely been some compromises made.\n",
    "But ... this is what we will be using.\n",
    "\n",
    "Nevertheless, we will now add some more meta-information about the speakers, etc. to these created hdf5 files so that these informations will be available, without the need for another feature extraction step (if the same acoustic features are to be used). e.g. label based on which gender is active, etc.\n",
    "\n",
    "\n",
    "```\n",
    "fisher.CallData(callid='00396', topicid='ENG28', signalgrade=4.0, convgrade=3.0, channelspeakers=\n",
    "\t\t[fisher.Speaker(pin='2215', gender='f', dialect='o'), \n",
    "\t\t fisher.Speaker(pin='4722', gender='f', dialect='a')])\n",
    "         \n",
    "```\n",
    "\n",
    "Lastly, for Viterbi Smoothing of the (expectedly) noisy soft-max posteriors from, the code below has been implemented to work from `InputsProviders`, even though we could have also extracted them from the label files (using the available `ActiveSpeakers.calc_raw_viterbi_priors(...)` method.\n",
    "This is more closer to the real data.\n",
    "\n",
    "The initial, transition and prior occurrences _(not normalized probabilities)_ will be calculated and added to the root level group `viterbi` in the respective hdf5 files of each split. \n",
    "Later, I believe, we will only ever be using the priors from the validation and training split, but it doesn't hurt to calculate from the testing set, does it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_viterbi_priors_from_ip(inputs_provider):\n",
    "    currn = None\n",
    "\n",
    "    init = None\n",
    "    tran = None\n",
    "    prior = None\n",
    "    for xy, (_, chunking) in inputs_provider.flow(\n",
    "            indefinitely=False,\n",
    "            only_labels=True,\n",
    "            with_chunking=True, ):\n",
    "\n",
    "        true = xy[1].astype(int)\n",
    "        if currn is None:  # first callid\n",
    "            currn = chunking.labelpath\n",
    "            init = true[0, ...]\n",
    "            prior = true.sum(axis=0)\n",
    "            tran = nu.confusion_matrix_forcategorical(true[:-1], true[1:])\n",
    "            continue\n",
    "        elif chunking.labelpath != currn:  # next callid\n",
    "            init += true[0, ...]\n",
    "            currn = chunking.labelpath\n",
    "            \n",
    "        \n",
    "        prior += true.sum(axis=0)\n",
    "        tran += nu.confusion_matrix_forcategorical(true[:-1], true[1:])\n",
    "\n",
    "    return init, tran, prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T16:48:44.754107",
     "start_time": "2017-08-04T16:48:44.700960"
    }
   },
   "outputs": [],
   "source": [
    "def checkh5_addinfo(pair, h5):\n",
    "    xsfs = expected_stridedfeat_shape(pair)\n",
    "    xsls = expected_stridedlabel_shape(pair)\n",
    "    \n",
    "    xdatachunks = ((xsfs[1], ) + xsfs[2:])\n",
    "    xlabelchunks = ((xsls[1], ) + xsls[2:])\n",
    "    \n",
    "    xdatashape = (xsfs[0] * xsfs[1], ) + xsfs[2:]\n",
    "    xlabelshape = (xsls[0] * xsls[1], ) + xsls[2:]\n",
    "    \n",
    "    l = pair.label\n",
    "    dp = fe.UnnormedFramewiseInputsProvider.for_callids(\n",
    "        h5,\n",
    "        l.callid,\n",
    "    )\n",
    "    \n",
    "    assert dp.totlen == xdatashape[0], \"Mismatch in audio len: {} v/s {}\".format(dp.totlen, xdatashape)\n",
    "    assert dp.totlen == xlabelshape[0], \"Mismatch in label len: {} v/s {}\".format(dp.totlen, xlabelshape)\n",
    "    \n",
    "    for c in dp.chunkings:\n",
    "        lend = c.dataslice[0].stop - c.dataslice[0].start\n",
    "        assert lend == xdatachunks[0], \"Mismatch in audio chunking: {} v/s {}\".format(lend, xdatachunks)\n",
    "        \n",
    "        lenl = c.labelslice[0].stop - c.labelslice[0].start\n",
    "        assert lenl == xlabelchunks[0], \"Mismatch in label chunking: {} v/s {}\".format(lenl, xlabelchunks)\n",
    "    \n",
    "    # Add infos\n",
    "    lp = dp.chunkings[0].labelpath\n",
    "    ap = dp.chunkings[0].datapath\n",
    "    calldata = l.calldata\n",
    "    \n",
    "    with h.File(h5, 'a') as f:\n",
    "        f[lp].attrs['speaker_pins'] = np.array([np.string_(s.pin) for s in calldata.channelspeakers])\n",
    "        f[lp].attrs['speaker_genders'] = np.array([np.string_(s.gender) for s in calldata.channelspeakers])\n",
    "        f[lp].attrs['speaker_dialects'] = np.array([np.string_(s.dialect) for s in calldata.channelspeakers])\n",
    "        \n",
    "        f[lp].attrs['topicid'] = calldata.topicid\n",
    "        f[lp].attrs['signalgrade'] = calldata.signalgrade\n",
    "        f[lp].attrs['convgrade'] = calldata.convgrade\n",
    "        \n",
    "        # FIXME: FUCK THIS SHIT\n",
    "#         f[lp].dims[1].label = np.string_('active_speaker_channel')\n",
    "#         f.create_dataset(\"labels/active_speaker_channels\", data=[0, 1])\n",
    "#         f[lp].dims[1].attach_scale(f[\"labels/active_speaker_channels\"])\n",
    "        \n",
    "#         f[ap].dims[1].label = np.string_('mel_frequencies')\n",
    "#         f.create_dataset(\"audios/mel_frequencies\", data=melfreq)\n",
    "#         f[lp].dims[1].attach_scale(f[\"audios/mel_frequencies\"])\n",
    "        \n",
    "        f.flush()\n",
    "            \n",
    "        return raw_viterbi_priors_from_ip(dp)\n",
    "        \n",
    "    \n",
    "def checkh5_addinfo_pairs(pairs, h5):\n",
    "    init = None\n",
    "    tran = None\n",
    "    prior = None\n",
    "    for i, pair in enumerate(pairs):\n",
    "        try:\n",
    "            _init, _tran, _prior = checkh5_addinfo(pair, h5)\n",
    "            if init is None:\n",
    "                init = _init.copy()\n",
    "                tran = _tran.copy()\n",
    "                prior = _prior.copy()\n",
    "            else:\n",
    "                init += _init\n",
    "                tran += _tran\n",
    "                prior += _prior\n",
    "            \n",
    "        except AssertionError as e:\n",
    "            print('AssertionErrors with pair at {}'.format(i))\n",
    "            print(fn_for_fp(pair.audio.filepath))\n",
    "            raise\n",
    "#             print(e)\n",
    "#             print()\n",
    "\n",
    "    # Add Viterbi Priors\n",
    "    with h.File(h5, 'a') as f:\n",
    "        g = f.create_group(\"viterbi\")\n",
    "        for d, p in zip((init, tran, prior), ('init', 'tran', 'priors')):\n",
    "            g.create_dataset(p, data=d)  # e.g. /viterbi/init\n",
    "        f.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T16:48:46.945433",
     "start_time": "2017-08-04T16:48:46.585128"
    }
   },
   "outputs": [],
   "source": [
    "checkh5_addinfo_pairs(val_pairs, val_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T16:48:55.559255",
     "start_time": "2017-08-04T16:48:48.508945"
    }
   },
   "outputs": [],
   "source": [
    "checkh5_addinfo_pairs(trn_pairs, trn_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T16:49:00.819856",
     "start_time": "2017-08-04T16:48:58.050576"
    }
   },
   "outputs": [],
   "source": [
    "checkh5_addinfo_pairs(tst_pairs, tst_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
